{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, target_list):\n",
    "        self.file_list = file_list\n",
    "        self.target_list = target_list\n",
    "        self.n_class = len(list(set(target_list)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(\"HI\")\n",
    "        #print(self.file_list[index])\n",
    "        img = Image.open(self.file_list[index])\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        if(self.file_list[index] == \"test_verification/299317.jpg\"):\n",
    "            print(\"Image\" , img)\n",
    "            print(\"Shape\",img.shape)\n",
    "        label = self.target_list[index]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the given directory to accumulate all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(datadir):\n",
    "    img_list = []\n",
    "    ID_list = []\n",
    "    for root, directories, filenames in os.walk(datadir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.jpg'):\n",
    "                filei = os.path.join(root, filename)\n",
    "                img_list.append(filei)\n",
    "                temp = filei.split('/')[-1]\n",
    "                #ID_list.append(root.split('/')[-1])\n",
    "                ID_list.append(int(temp.split('.')[0]))\n",
    "    print(img_list[:10])\n",
    "    print(ID_list[:10])\n",
    "    # construct a dictionary, where key and value correspond to ID and target\n",
    "    uniqueID_list = list(set(ID_list))\n",
    "    class_n = len(uniqueID_list)\n",
    "    target_dict = dict(zip(uniqueID_list, range(class_n)))\n",
    "    label_list = [target_dict[ID_key] for ID_key in ID_list]\n",
    "\n",
    "    print('{}\\t\\t{}\\n{}\\t\\t{}'.format('#Images', '#Labels', len(img_list), len(set(label_list))))\n",
    "    return img_list, ID_list, class_n , target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_verification/317667.jpg', 'test_verification/234228.jpg', 'test_verification/351500.jpg', 'test_verification/207801.jpg', 'test_verification/349870.jpg', 'test_verification/325224.jpg', 'test_verification/331654.jpg', 'test_verification/230454.jpg', 'test_verification/316397.jpg', 'test_verification/311255.jpg']\n",
      "[317667, 234228, 351500, 207801, 349870, 325224, 331654, 230454, 316397, 311255]\n",
      "#Images\t\t#Labels\n",
      "169392\t\t169392\n"
     ]
    }
   ],
   "source": [
    "img_list, label_list, class_n ,dictionary = parse_data('test_verification')\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelU(nn.Module):\n",
    "    def __init__(self,in_channel, out_channel, kernel_size, stride):\n",
    "        super(ConvBNRelU, self).__init__()\n",
    "        if(kernel_size==1):\n",
    "            self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        else:\n",
    "            if(in_channel == out_channel):\n",
    "                self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=1, groups = out_channel,bias=False)\n",
    "            else:\n",
    "                self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu6 = nn.ReLU6(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.relu6(self.bn1(self.conv1(x)))\n",
    "        \n",
    "#ConvBNRelU(16,16,6,2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channel, out_channel,expansion_factor,stride):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride=stride\n",
    "        self.expansion_factor = expansion_factor\n",
    "        \n",
    "        if(self.expansion_factor == 1):\n",
    "            self.convbn3 = ConvBNRelU(in_channel, in_channel, 3, stride)\n",
    "        else:\n",
    "            self.convbn1 = ConvBNRelU(in_channel, expansion_factor*in_channel, 1, 1)\n",
    "            self.convbn3 = ConvBNRelU(expansion_factor*in_channel, expansion_factor*in_channel, 3, stride)\n",
    "        \n",
    "        self.conv = nn.Conv2d(expansion_factor*in_channel, out_channel, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        \n",
    "        if(self.stride==1):\n",
    "            self.shortcut = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, bias=False)\n",
    "            \n",
    "    \n",
    "    def forward(self,x):\n",
    "        if(self.stride==1):\n",
    "            if(self.expansion_factor==1):\n",
    "                output= self.bn1(self.conv(self.convbn3(x)))\n",
    "            else:\n",
    "                output=self.bn1(self.conv(self.convbn3(self.convbn1(x))))\n",
    "            return output + self.shortcut(x)\n",
    "            return output\n",
    "        else:\n",
    "            return self.bn1(self.conv(self.convbn3(self.convbn1(x))))\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "# net=nn.Sequential(*[InvertedResidual(32,16,1,1)])   \n",
    "# print(net)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model with Residual Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_MobileNet(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_sizes, num_classes, feat_dim, expansion_factor_list, strides_list, repeat_list):\n",
    "        super(Network_MobileNet, self).__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        self.layers.append(ConvBNRelU(input_channels,hidden_sizes[0], 3, 2))\n",
    "        #self.layers.append(nn.BatchNorm2d(hidden_sizes[0]))\n",
    "        #self.layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        for idx in range(len(hidden_sizes)-1):\n",
    "            \n",
    "            for j in range(repeat_list[idx]):\n",
    "                \n",
    "                if(j==0):\n",
    "                    self.layers.append(InvertedResidual(hidden_sizes[idx], hidden_sizes[idx+1], expansion_factor_list[idx],strides_list[idx]))\n",
    "                else:\n",
    "                    self.layers.append(InvertedResidual(hidden_sizes[idx+1], hidden_sizes[idx+1], expansion_factor_list[idx],1))\n",
    "                    \n",
    "        \n",
    "        self.layers.append(ConvBNRelU(hidden_sizes[-1],1280, 1, 1))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.classifier = nn.Sequential(*[nn.Linear(1280,2300,bias=True)])\n",
    "        #print(self.layers[-1].conv1.weight.shape)\n",
    "        #self.classifier = nn.Linear(1280,2300,bias=True)\n",
    "        #self.classifier = nn.Linear(1280,2300,bias=True)\n",
    "        \n",
    "        #print(self.layers)\n",
    "        \n",
    "        #print(self.layers)\n",
    "        #self.linear_label = nn.Linear(self.hidden_sizes[-2], self.hidden_sizes[-1], bias=False)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x, evalMode=False):\n",
    "        output=x\n",
    "        output=self.layers(output)\n",
    "#         temp =output\n",
    "#         output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)\n",
    "#         output = output.reshape(output.shape[0], output.shape[1])\n",
    "        \n",
    "#         label_output=self.classifier(output)\n",
    "#         #print(\"WEIGHTS\",self.classifier[0].weight.shape)\n",
    "#         #label_output = label_output / torch.norm(self.classifier.weight, dim=1)\n",
    "#         label_output = label_output / torch.norm(self.classifier[0].weight, dim=1)\n",
    "        print(\"First output\" , output)\n",
    "        temp =output\n",
    "        output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)\n",
    "        print(\"Second output\" , output)\n",
    "        output = output.reshape(output.shape[0], output.shape[1])\n",
    "        print(\"Third output\" , output)\n",
    "        label_output=self.classifier(output)\n",
    "        print(\"Fourth output\" , label_output)\n",
    "        #print(\"WEIGHTS\",self.classifier[0].weight.shape)\n",
    "        label_output = label_output / torch.norm(self.classifier[0].weight, dim=1)\n",
    "        print(\"Fifth output\" , label_output)\n",
    "        \n",
    " \n",
    "\n",
    "        return None, label_output\n",
    "        \n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        \n",
    "        \n",
    "# input_channels=3\n",
    "# hidden_sizes=[32,16,24,32,64,96,160,320]\n",
    "# repeat_list=[1,2,3,4,3,3,1]\n",
    "# strides_list=[1,2,2,2,1,2,1]\n",
    "# expansion_factor_list=[1,6,6,6,6,6,6]\n",
    "# x=Network_MobileNet(input_channels ,hidden_sizes ,10,10 , expansion_factor_list ,strides_list , repeat_list)\n",
    "# print(self.classifier[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader,task='Classification'):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(start_epoch, numEpochs):\n",
    "        avg_loss = 0.0\n",
    "        \n",
    "\n",
    "#         lr = learningRate * (0.1)\n",
    "        \n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             param_group['lr'] = lr\n",
    "        \n",
    "        print(\"Entered epoch\")\n",
    "        for batch_num, (feats, labels) in enumerate(data_loader):\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feats)[1]\n",
    "\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            if batch_num % 50 == 49:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n",
    "                avg_loss = 0.0    \n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "            del loss\n",
    "            \n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': network.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "        },\"model_params_new\" + str(epoch) + \".tar\" )\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"Finished one loop\")\n",
    "            #break\n",
    "        #print(\"One epoch passed\")\n",
    "        #break\n",
    "        \n",
    "#         if task == 'Classification':\n",
    "#             val_loss, val_acc = test_classify(model, test_loader)\n",
    "#             train_loss, train_acc = test_classify(model, data_loader)\n",
    "#             print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
    "#                   format(train_loss, train_acc, val_loss, val_acc))\n",
    "#         else:\n",
    "#             test_verify(model, test_loader)\n",
    "\n",
    "\n",
    "def test_classify(model, test_loader):\n",
    "    print(\"HI\")\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    pred_label_list=np.zeros((1))\n",
    "    id1=np.zeros(1)\n",
    "    i=5000\n",
    "    \n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)[1]\n",
    "        #print(i)\n",
    "        \n",
    "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "        #print(pred_labels.flatten())\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        #id1=i.to(device)\n",
    "        \n",
    "        #print(\"Batch num\",batch_num)\n",
    "        #x=np.ndarray.flatten(id1.data.cpu().numpy())\n",
    "            \n",
    "        #y= np.ndarray.flatten(pred_labels.data.cpu().numpy())\n",
    "        x=np.ndarray.flatten(pred_labels.data.cpu().numpy())\n",
    "           \n",
    "        #x_y = np.append(x,y)\n",
    "        #print(x_y)\n",
    "        \n",
    "        pred_label_list= np.vstack((pred_label_list,x))\n",
    "        id1=np.vstack((id1,i))\n",
    "        \n",
    "        #print(id1)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        del feats\n",
    "        del labels\n",
    "        i+=1\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(test_loss), accuracy/total , pred_label_list[1:,:],id1[1:,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"test_trials_verification_student.txt\", \"r\") as myfile:\n",
    "    data=myfile.readlines()\n",
    "\n",
    "image_pair_list=[]\n",
    "for i in range(len(data)):\n",
    "  \n",
    "    image_pair_list.append(data[i].replace(\"\\n\",\"\").split(\" \"))\n",
    "    #print(image_pair_list)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(image_pair_list))\n",
    "path=\"/home/ubuntu/hw2part2/test_verification/\"\n",
    "\n",
    "\n",
    "\n",
    "def test_verify(model):\n",
    "    #score_list=np.zeros((1))\n",
    "    #file_list =np.zeros((1))\n",
    "    model.eval()\n",
    "    with open(\"output_verification2.csv\",'a+') as outfile:\n",
    "        for i in range(len(image_pair_list)):\n",
    "            print(i)\n",
    "            image1_name,image2_name = image_pair_list[i][0], image_pair_list[i][1]\n",
    "            img1, img2 = Image.open(path+image1_name),Image.open(path+image2_name)\n",
    "            img1, img2 = torchvision.transforms.ToTensor()(img1),torchvision.transforms.ToTensor()(img2)\n",
    "            im1, im2 = torch.cuda.FloatTensor(np.array(img1).reshape((1,3,32,32))),torch.cuda.FloatTensor(np.array(img2).reshape((1,3,32,32)))\n",
    "            print(\"Image1\",im1)\n",
    "            output1, output2 = model(im1)[1] , model(im2)[1]\n",
    "            print(\"output1\",output1)\n",
    "            print(\"output2\",output2)\n",
    "            cos = nn.CosineSimilarity(dim=1 ,eps=1e-08)\n",
    "            score = cos(output1, output2).cpu().detach()\n",
    "            #norm_op1 ,norm_op2= F.softmax(output1, dim=1),F.softmax(output2, dim=1)            \n",
    "            #l2 = nn.PairwiseDistance(p=2)\n",
    "            #score = l2(norm_op1,norm_op2)\n",
    "            print(\"SCore\",score)\n",
    "            \n",
    "            filename = image1_name + \" \" + image2_name\n",
    "            outfile.write(filename + \",\" + str(float(score)) + '\\n')\n",
    "            #break\n",
    "            #score1=np.ndarray.flatten(score.data.cpu().numpy())\n",
    "        #score_list=np.vstack((score_list,score1))\n",
    "        \n",
    "        #file_list=np.vstack((file_list,np.array([image1_name + \" \" + image2_name])))\n",
    "        #print(file_list)\n",
    "            #if(i==20):\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset, DataLoader and Constant Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='train_data/medium/', \n",
    "                                                 transform=torchvision.transforms.ToTensor())\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, \n",
    "                                               shuffle=True, num_workers=8)\n",
    "\n",
    "\n",
    "\n",
    "# dev_dataset = torchvision.datasets.ImageFolder(root='medium_dev/', \n",
    "#                                                transform=torchvision.transforms.ToTensor())\n",
    "# dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=10, \n",
    "#                                              shuffle=True, num_workers=8)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='test_classification/', \n",
    "                                               transform=torchvision.transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, \n",
    "                                             shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "#test_verification = torchvision.datasets.ImageFolder(root='test_verification/', \n",
    "                                               #transform=torchvision.transforms.ToTensor())\n",
    "#test_verify_dataloader = torch.utils.data.DataLoader(test_verification, batch_size=1, \n",
    "                                             #shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network(num_feats, hidden_sizes, num_classes)\n",
    "input_channels=3\n",
    "hidden_sizes=[32,16,24,32,64,96,160,320]\n",
    "repeat_list=[1,2,3,4,3,3,1]\n",
    "strides_list=[1,1,1,1,1,2,2]\n",
    "expansion_factor_list=[1,6,6,6,6,6,6]\n",
    "learningRate = 3e-2\n",
    "weightDecay = 5e-5\n",
    "network = Network_MobileNet(input_channels ,hidden_sizes ,10,10 , expansion_factor_list ,strides_list , repeat_list)\n",
    "network.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9 ,nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered epoch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a2cd87c77e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnumEpochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-95e8597879ba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, task)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network.train()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "network.to(device)\n",
    "\n",
    "checkpoint = torch.load(\"model_params_new_11.tar\")   \n",
    "network.cuda()\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "start_epoch = epoch\n",
    "numEpochs = 15\n",
    "train(network, train_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#             'epoch': 11,\n",
    "#             'model_state_dict': network.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': 0.6588,\n",
    "#             },\"model_params_new_11\" + \".tar\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_params_new_11.tar\")   \n",
    "network.cuda()\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# lr = learningRate * (0.1 ** (epoch // 1))\n",
    "# for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ImageDataset(img_list , label_list)\n",
    "test_verification_loader = DataLoader(testset , batch_size = 2048 , shuffle =False , num_workers =0 , drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model , test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        output_array = {}\n",
    "        for batch_idx , (data , target) in enumerate(test_loader):\n",
    "            #print(target)\n",
    "            #target1=target.data.numpy()\n",
    "            #print(type(target1))\n",
    "   \n",
    "                \n",
    "            start_time = time.time()\n",
    "            data = data.to(device)\n",
    "            print(\"Shape\",data.shape)\n",
    "            embedding = model(data)[1]\n",
    "            for i in range(target.shape[0]):\n",
    "                output_array[str(target[i].item())] = embedding[i]\n",
    "                \n",
    "            end_time = time.time()\n",
    "            print(\"Time \",str(end_time - start_time))\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = verify(network, test_verification_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1 ,eps=1e-08)\n",
    "image1 =[]\n",
    "image2 = []\n",
    "with open('test_trials_verification_student.txt' , 'r') as file:\n",
    "    for line in file:\n",
    "        temp1 = line.split()[0]\n",
    "        temp2 = line.split()[1]\n",
    "        image1.append(temp1.split('.')[0])\n",
    "        image2.append(temp2.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['299317.jpg 248776.jpg', 0.6447991728782654]\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "for x,y in zip(image1, image2):\n",
    "    value = cos(embeddings[x].reshape(1,-1) , embeddings[y].reshape(1,-1))\n",
    "    answer.append([str(x) + '.jpg' + ' ' + str(y) + '.jpg' , value.item()])\n",
    "print(answer[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('v.csv' , 'w' , newline='')\n",
    "with file:\n",
    "    a=csv.writer(file)\n",
    "    a.writerows(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.7152,  2.6177, -1.8686,  ..., -0.2592, -3.2146, -1.3829],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#print(embeddings.keys())\n",
    "print(embeddings['299317'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Image1 tensor([[[[0.5725, 0.4118, 0.4431,  ..., 0.6980, 0.6902, 0.7020],\n",
      "          [0.6157, 0.4392, 0.4431,  ..., 0.6667, 0.6941, 0.7098],\n",
      "          [0.6745, 0.4941, 0.4863,  ..., 0.6588, 0.6745, 0.6745],\n",
      "          ...,\n",
      "          [0.2353, 0.1412, 0.2275,  ..., 0.4275, 0.4863, 0.4039],\n",
      "          [0.4235, 0.3569, 0.3490,  ..., 0.5412, 0.5216, 0.4275],\n",
      "          [0.4078, 0.3804, 0.3490,  ..., 0.5843, 0.4863, 0.4980]],\n",
      "\n",
      "         [[0.4275, 0.2667, 0.2980,  ..., 0.5059, 0.4980, 0.5098],\n",
      "          [0.4706, 0.2941, 0.2980,  ..., 0.4745, 0.5020, 0.5176],\n",
      "          [0.5216, 0.3412, 0.3333,  ..., 0.4667, 0.4824, 0.4824],\n",
      "          ...,\n",
      "          [0.1608, 0.0549, 0.1255,  ..., 0.2941, 0.3725, 0.3020],\n",
      "          [0.3569, 0.2706, 0.2353,  ..., 0.3922, 0.4000, 0.3137],\n",
      "          [0.3373, 0.2902, 0.2235,  ..., 0.4235, 0.3529, 0.3765]],\n",
      "\n",
      "         [[0.5882, 0.4275, 0.4588,  ..., 0.7255, 0.7176, 0.7294],\n",
      "          [0.6314, 0.4549, 0.4588,  ..., 0.6941, 0.7216, 0.7373],\n",
      "          [0.6941, 0.5137, 0.5059,  ..., 0.6824, 0.6980, 0.6980],\n",
      "          ...,\n",
      "          [0.2353, 0.1373, 0.2314,  ..., 0.4314, 0.4941, 0.4157],\n",
      "          [0.4275, 0.3608, 0.3569,  ..., 0.5529, 0.5333, 0.4314],\n",
      "          [0.4235, 0.4000, 0.3765,  ..., 0.5961, 0.4902, 0.4980]]]],\n",
      "       device='cuda:0')\n",
      "output1 tensor([[ 3.7152,  2.6177, -1.8686,  ..., -0.2592, -3.2146, -1.3829]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "SCore tensor([0.6448])\n"
     ]
    }
   ],
   "source": [
    "#network.load_state_dict(torch.load(\"model_params_new.tar\"))\n",
    "\n",
    "score= test_verify(network)\n",
    "# print(file_list)\n",
    "# print(score_list)\n",
    "# output = np.hstack((file_list,score_list))\n",
    "# np.savetxt(\"output_verification_1.csv\", output, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = torch.load(\"model_params_new.tar\")\n",
    "# network.cuda()\n",
    "# network.load_state_dict(checkpoint['model_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# network.eval()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mean,accuracy,pred_list,id1 = test_classify(network, test_dataloader)\n",
    "#print(pred_list.shape)\n",
    "#print(id1.shape)\n",
    "#print(pred_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000.  947.]\n"
     ]
    }
   ],
   "source": [
    "#print(pred_list[0])\n",
    "#print(pred_list)\n",
    "dictionary1=train_dataset.classes\n",
    "pred_list1 = np.zeros(1)\n",
    "for i in range(pred_list.shape[0]):\n",
    "    #pred_list1=np.vstack((pred_list1,dictionary[str(int(pred_list[i][0]))]))\n",
    "    #print(pred_list[i][0])\n",
    "    #print(dictionary1[int(pred_list[i][0])])\n",
    "    pred_list1=np.vstack((pred_list1, float(dictionary1[int(pred_list[i][0])])))\n",
    "\n",
    "output=np.hstack((id1,pred_list1[1:]))\n",
    "#print(output.shape)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"output_classification_7.csv\", output, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
